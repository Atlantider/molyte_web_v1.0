# 轮询 Worker 配置文件（腾讯云版本）

# 腾讯云 API 配置
api:
  # 腾讯云后端 API 地址
  base_url: "https://www.molyte.xyz/api/v1"
  
  # Worker 认证 Token（在腾讯云后端创建专用的 Worker 用户）
  worker_token: "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJ3b3JrZXIiLCJleHAiOjE3OTYxMTIzMTJ9.1lXixHDkAD4oqBHQiPAPdo0D0uHY6te6H-X7607Ie9o"
  
  # 轮询间隔（秒）
  poll_interval: 30
  
  # 请求超时（秒）
  timeout: 60

# 腾讯云 COS 配置
cos:
  # SecretId（在腾讯云控制台 -> 访问管理 -> API密钥管理 中获取）
  secret_id: "AKIDNqAKH4e1EH7mEWhDbswmU6asxsa5NUeg"
  
  # SecretKey
  secret_key: "teGhwyoSt9B3iAOPFxSltpY3LcicIo7l"
  
  # COS 地域（ap-beijing, ap-shanghai, ap-guangzhou 等）
  region: "ap-beijing"
  
  # Bucket 名称（格式：bucket-appid）
  bucket: "molyte-results-1308567295"
  
  # 结果文件路径前缀
  result_prefix: "results/"

# 本地计算环境配置（校园网集群）
local:
  # Molyte 工作目录
  work_base_path: "/public/home/xiaoji/molyte_web/data/md_work"
  
  # QC 工作目录
  qc_work_base_path: "/public/home/xiaoji/molyte_web/data/qc_work"
  
  # 初始盐文件路径
  initial_salts_path: "/public/home/xiaoji/molyte_web/data/initial_salts"
  
  # LigParGen 路径
  ligpargen_path: "/public/software/anaconda3/envs/molyte/bin"
  
  # Packmol 路径
  packmol_path: "/public/software/packmol-20.16.0/packmol"
  
  # Moltemplate 路径
  ltemplify_path: "/public/software/moltemplate_2025-2-02/moltemplate/ltemplify.py"
  moltemplate_path: "/public/software/moltemplate_2025-2-02/moltemplate/scripts/moltemplate.sh"
  
  # 电荷文件保存路径
  charge_save_path: "/public/home/xiaoji/molyte_web/data/charges"
  
  # Conda 环境
  conda_env: "molyte"
  conda_activate: "/public/software/anaconda3/bin/activate"

# Worker 配置
worker:
  # Worker 名称（用于标识）
  name: "campus-worker-01"
  
  # 最大并发任务数
  max_concurrent_jobs: 3
  
  # 任务类型（支持的任务类型）
  supported_job_types:
    - "MD"
    - "QC"
  
  # 日志配置
  log_file: "/tmp/polling_worker.log"
  log_level: "INFO"
  
  # 心跳间隔（秒）
  heartbeat_interval: 60

# Slurm 配置
slurm:
  # 默认分区
  default_partition: "cpu"
  
  # 任务状态检查间隔（秒）
  status_check_interval: 60
  
  # 最大重试次数
  max_retries: 3

# 文件上传配置
upload:
  # 需要上传的文件类型（分优先级）
  # 优先级 1: 必须上传的小文件
  essential_files:
    - "*.data"          # LAMMPS 数据文件
    - "*.log"           # 日志文件
    - "*.xlsx"          # 分析结果
    - "*.png"           # 图表
    - "*.json"          # JSON 结果
    - "*.fchk"          # Gaussian 检查点

  # 优先级 2: 可选的大文件（Cube 等）
  optional_large_files:
    - "*.cube"          # Gaussian Cube 文件（可能很大）

  # 明确排除的文件（不上传）
  excluded_files:
    - "*.dump"          # LAMMPS 轨迹文件（太大，不上传）
    - "*.trj"           # 轨迹文件（太大，不上传）
    - "*.dcd"           # 二进制轨迹（太大，不上传）
    - "*.xtc"           # 压缩轨迹（太大，不上传）
    - "*_traj_*"        # 任何轨迹相关文件

  # 文件大小限制
  max_file_size: 2048        # 单个文件最大 2GB
  multipart_threshold: 100   # 超过 100MB 使用分片上传
  part_size: 10              # 分片大小 10MB

  # 压缩配置
  compress_large_files: true
  compress_threshold: 50     # 超过 50MB 自动压缩
  compress_format: "gzip"    # 压缩格式: gzip, bz2, xz

  # 轨迹文件特殊处理
  trajectory_handling:
    enabled: true
    # 不上传完整轨迹文件
    upload_full_trajectory: false
    # 只提取并上传最后一帧作为 PDB/XYZ
    extract_last_frame: true
    last_frame_format: "pdb"  # pdb, xyz, data
    # 保留本地轨迹文件（用户可以手动下载）
    keep_local_trajectory: true
    local_retention_days: 30  # 本地保留 30 天

  # 上传策略
  strategy:
    # 总是上传 essential_files
    upload_essential: true
    # 只在用户请求时上传 optional_large_files
    upload_optional_on_demand: true
    # 删除本地文件前确认云端上传成功
    verify_upload: true
    # 上传失败重试次数
    max_retries: 3

# 错误处理
error_handling:
  # 任务失败后重试次数
  max_task_retries: 2
  
  # 重试延迟（秒）
  retry_delay: 300
  
  # 网络错误重试次数
  network_retry: 5
  
  # 网络错误重试延迟（秒）
  network_retry_delay: 10

